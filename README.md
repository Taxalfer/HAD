# HAD
## abstract
RGB cameras excel at capturing rich texture details and high spatial resolution, whereas event cameras offer exceptional temporal resolution and high dynamic range (HDR). Leveraging these complementary advantages can significantly improve object tracking under challenging scenarios, including high-speed motion, HDR environments, and dynamic background interference. However, substantial spatiotemporal asymmetry exists between these two modalities due to their fundamentally different imaging mechanisms, hindering effective multi-modal integration. To address this critical issue, we propose Hierarchical Asymmetric Distillation (HAD), a novel multi-modal knowledge distillation framework that explicitly models and conquers asymmetry information in spatio-temporal dimensions. Specifically, HAD introduces a hierarchical alignment strategy that mitigates information loss while maintaining the student network's computational efficiency and parameter count. Extensive experimental evaluations demonstrate the superiority of HAD over existing methods, and comprehensive ablation studies validate the effectiveness and necessity of each designed component.
